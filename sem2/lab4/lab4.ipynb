{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-11T19:59:20.966693Z","iopub.execute_input":"2025-12-11T19:59:20.967021Z","iopub.status.idle":"2025-12-11T19:59:20.972727Z","shell.execute_reply.started":"2025-12-11T19:59:20.966998Z","shell.execute_reply":"2025-12-11T19:59:20.971523Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Обучим MLP из библиотеки Scikit Learn","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_openml\n\nmnist = fetch_openml('mnist_784', version=1, as_frame=False)\nX, y = mnist.data, mnist.target\nX /= 255.0\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, shuffle=True, test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T19:56:30.004835Z","iopub.execute_input":"2025-12-11T19:56:30.005149Z","iopub.status.idle":"2025-12-11T19:56:59.543686Z","shell.execute_reply.started":"2025-12-11T19:56:30.005125Z","shell.execute_reply":"2025-12-11T19:56:59.542581Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n  warn(\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nmodel = MLPClassifier()\nmodel.fit(X_train, y_train)\n\npreds = model.predict(X_test)\nprint('Accuracy:', accuracy_score(y_test, preds))\nprint('F1 micro:', f1_score(y_test, preds, average='micro'))\nprint('F1 macro:', f1_score(y_test, preds, average='macro'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:00:41.169909Z","iopub.execute_input":"2025-12-11T20:00:41.170254Z","iopub.status.idle":"2025-12-11T20:01:53.340192Z","shell.execute_reply.started":"2025-12-11T20:00:41.170232Z","shell.execute_reply":"2025-12-11T20:01:53.339090Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9763571428571428\nF1 micro: 0.9763571428571428\nF1 macro: 0.9762537196331811\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Построим CNN по типу LeNet и обучим её на датасете MNIST","metadata":{}},{"cell_type":"code","source":"from torchvision import models\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nimport torch\nimport warnings\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:05:01.741942Z","iopub.execute_input":"2025-12-11T20:05:01.742275Z","iopub.status.idle":"2025-12-11T20:05:01.748043Z","shell.execute_reply.started":"2025-12-11T20:05:01.742253Z","shell.execute_reply":"2025-12-11T20:05:01.746621Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class MNIST(Dataset):\n    def __init__(self, X, y, transform=None):\n        self.X = X\n        self.y = y\n        self.transform = T.Compose([\n            T.ToPILImage(),\n            T.ToTensor(),\n            T.Normalize((0.1307,), (0.3081,))\n        ])\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        image = self.X[idx].reshape(28, 28).astype(np.uint8)\n        image = self.transform(image)\n            \n        return image, int(self.y[idx])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:12:36.965208Z","iopub.execute_input":"2025-12-11T20:12:36.965527Z","iopub.status.idle":"2025-12-11T20:12:36.972924Z","shell.execute_reply.started":"2025-12-11T20:12:36.965506Z","shell.execute_reply":"2025-12-11T20:12:36.971923Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"mnist = fetch_openml('mnist_784', version=1, as_frame=False)\nX, y = mnist.data, mnist.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, shuffle=True, test_size=0.25)\n\ntrain_dataset = MNIST(X_train, y_train, transform=transform)\ntest_dataset = MNIST(X_test, y_test, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:12:37.167469Z","iopub.execute_input":"2025-12-11T20:12:37.168485Z","iopub.status.idle":"2025-12-11T20:12:58.947796Z","shell.execute_reply.started":"2025-12-11T20:12:37.168453Z","shell.execute_reply":"2025-12-11T20:12:58.946642Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n  warn(\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass CNN(nn.Module):\n\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.linear1   = nn.Linear(400, 120)\n        self.linear2   = nn.Linear(120, 84)\n        self.linear3   = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n        x = x.view(-1, np.prod(x.size()[1:]))\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:13:55.324282Z","iopub.execute_input":"2025-12-11T20:13:55.325117Z","iopub.status.idle":"2025-12-11T20:13:55.332675Z","shell.execute_reply.started":"2025-12-11T20:13:55.325090Z","shell.execute_reply":"2025-12-11T20:13:55.331376Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def train(epochs):\n    train_losses, train_accuracies = [], []\n    test_losses, test_accuracies = [], []\n    for epoch in range(1, epochs + 1):\n        train_loss, train_accuracy = 0.0, 0.0\n        model.train()\n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            logits = model(images)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * images.shape[0]\n            train_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n        \n        train_loss /= len(train_loader.dataset)\n        train_accuracy /= len(train_loader.dataset)\n\n        scheduler.step()\n        \n        test_loss, test_accuracy = 0.0, 0.0\n        model.eval()\n        for images, labels in test_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            with torch.no_grad():\n                logits = model(images)\n                loss = criterion(logits, labels)\n\n            test_loss += loss.item() * images.shape[0]\n            test_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n\n        test_loss /= len(test_loader.dataset)\n        test_accuracy /= len(test_loader.dataset)\n        \n        \n        train_losses += [train_loss]\n        train_accuracies += [train_accuracy]\n        test_losses += [test_loss]\n        test_accuracies += [test_accuracy]\n\n        print(f'Epoch: {epoch}, train_loss: {train_loss}, test_loss: {test_loss}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:35:41.651943Z","iopub.execute_input":"2025-12-11T20:35:41.652393Z","iopub.status.idle":"2025-12-11T20:35:41.663830Z","shell.execute_reply.started":"2025-12-11T20:35:41.652365Z","shell.execute_reply":"2025-12-11T20:35:41.662735Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"model = CNN()\noptimizer = torch.optim.Adam(model.parameters())\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\ncriterion = nn.CrossEntropyLoss() \ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:43:41.999027Z","iopub.execute_input":"2025-12-11T20:43:41.999436Z","iopub.status.idle":"2025-12-11T20:43:42.008914Z","shell.execute_reply.started":"2025-12-11T20:43:41.999338Z","shell.execute_reply":"2025-12-11T20:43:42.007548Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"train(8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:43:42.751539Z","iopub.execute_input":"2025-12-11T20:43:42.752848Z","iopub.status.idle":"2025-12-11T20:47:12.749750Z","shell.execute_reply.started":"2025-12-11T20:43:42.752811Z","shell.execute_reply":"2025-12-11T20:47:12.748629Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1, train_loss: 0.3424120650798792, test_loss: 0.11195711160898209\nEpoch: 2, train_loss: 0.08913182769275847, test_loss: 0.07002112916026797\nEpoch: 3, train_loss: 0.05973386781499499, test_loss: 0.051833647218772344\nEpoch: 4, train_loss: 0.04378662882979427, test_loss: 0.05209189014605113\nEpoch: 5, train_loss: 0.03378710383034888, test_loss: 0.04729568531853812\nEpoch: 6, train_loss: 0.02737112624247869, test_loss: 0.041883145223345075\nEpoch: 7, train_loss: 0.021968932999635028, test_loss: 0.04007958917958396\nEpoch: 8, train_loss: 0.018976253450750595, test_loss: 0.03676403621860913\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"y_pred = []\nmodel.eval()\nfor images, labels in test_loader:\n    images = images.to(device)\n    labels = labels.to(device)\n    with torch.no_grad():\n        logits = model(images)\n        y_pred += logits.argmax(dim=1).tolist()\ny_test = list(map(int, y_test))\nprint('Accuracy:', accuracy_score(y_test, y_pred))\nprint('F1 micro:', f1_score(y_test, y_pred, average='micro'))\nprint('F1 macro:', f1_score(y_test, y_pred, average='macro'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T20:47:16.615494Z","iopub.execute_input":"2025-12-11T20:47:16.615885Z","iopub.status.idle":"2025-12-11T20:47:22.416646Z","shell.execute_reply.started":"2025-12-11T20:47:16.615862Z","shell.execute_reply":"2025-12-11T20:47:22.415530Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9879428571428571\nF1 micro: 0.9879428571428571\nF1 macro: 0.9878750328689254\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"Вывод:\nВ силу того, что сверточные нейронные сети лучше подходят для решения задач классификации результаты у модели LeNet получились лучше. Это подтверждается метриками, так как Accuracy и F1-score у LeNet лучше чем у MLP","metadata":{}}]}