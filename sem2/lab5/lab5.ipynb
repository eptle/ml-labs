{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7683878,"sourceType":"datasetVersion","datasetId":4483363}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Подготим сначала датасет по текстовому файлу. Создадим для этого специальный класс","metadata":{}},{"cell_type":"code","source":"import sentencepiece as spm\nfrom sentencepiece import SentencePieceProcessor, SentencePieceTrainer\nimport numpy as np\nimport tensorflow as tf\n\nclass TextDataset:\n    \n    def __init__(self, data_file, sp_model_prefix, vocab_size = 2000, normalization_rule_name = 'nmt_nfkc_cf',\n                 model_type = 'bpe', max_length = 128):\n\n        SentencePieceTrainer.train(input=data_file, vocab_size=vocab_size, model_type=model_type, model_prefix=sp_model_prefix,\n            normalization_rule_name=normalization_rule_name, pad_id=0, bos_id=1, eos_id=2, unk_id=3)\n        \n        self.sp_model = SentencePieceProcessor(model_file=sp_model_prefix + '.model')\n        \n        with open(data_file, 'r', encoding='utf-8') as file:\n            self.texts = [line.strip() for line in file.readlines()]\n        \n        self.max_length = max_length\n        self.vocab_size = self.sp_model.vocab_size()\n        self._encoded_cache = None\n        \n    def encode_texts(self):\n        if self._encoded_cache is not None:\n            return self._encoded_cache\n        sequences = []\n        targets = []\n        for text in self.texts:\n            encoded = self.sp_model.encode(text)\n            if len(encoded) > self.max_length - 2:\n                encoded = encoded[:self.max_length - 2]\n            sequence = [self.sp_model.bos_id()] + encoded + [self.sp_model.eos_id()]\n            if len(sequence) < self.max_length:\n                sequence = sequence + [self.sp_model.pad_id()] * (self.max_length - len(sequence))\n            else:\n                sequence = sequence[:self.max_length]\n            target = sequence[1:] + [self.sp_model.pad_id()]\n            sequences.append(sequence)\n            targets.append(target)\n        self._encoded_cache = (np.array(sequences), np.array(targets))\n        return self._encoded_cache\n    \n    def create_tf_dataset(self, batch_size = 32, shuffle = True):\n        sequences, targets = self.encode_texts()\n        dataset = tf.data.Dataset.from_tensor_slices((sequences, targets))\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=len(sequences))\n        dataset = dataset.batch(batch_size)\n        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n        return dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:09:22.731460Z","iopub.execute_input":"2025-12-12T14:09:22.732100Z","iopub.status.idle":"2025-12-12T14:09:22.740654Z","shell.execute_reply.started":"2025-12-12T14:09:22.732074Z","shell.execute_reply":"2025-12-12T14:09:22.740029Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"Загрузим датасет из файла","metadata":{}},{"cell_type":"code","source":"dataset = TextDataset(data_file=\"dataset.txt\", sp_model_prefix=\"jokes_spm\", vocab_size=2000, max_length=100)\n\nX, y = dataset.encode_texts()\ntf_dataset = dataset.create_tf_dataset(batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:09:44.531593Z","iopub.execute_input":"2025-12-12T14:09:44.532356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Создадим и обучим рекуррентную сеть на основе LSTM","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n\nmodel = Sequential([\n    Embedding(input_dim=dataset.vocab_size, output_dim=128, input_length=dataset.max_length, mask_zero=True),\n    Bidirectional(LSTM(256, return_sequences=True)),\n    Dropout(0.3),\n    LSTM(256, return_sequences=True),\n    Dropout(0.3),\n    Dense(dataset.vocab_size, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(tf_dataset, epochs=10, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2025-12-12T13:46:45.450265Z","iopub.execute_input":"2025-12-12T13:46:45.450539Z","iopub.status.idle":"2025-12-12T14:04:14.544454Z","shell.execute_reply.started":"2025-12-12T13:46:45.450519Z","shell.execute_reply":"2025-12-12T14:04:14.543685Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 28ms/step - accuracy: 0.0853 - loss: 4.8587\nEpoch 2/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 28ms/step - accuracy: 0.3270 - loss: 0.7651\nEpoch 3/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 28ms/step - accuracy: 0.3885 - loss: 0.1167\nEpoch 4/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 28ms/step - accuracy: 0.3954 - loss: 0.0297\nEpoch 5/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 28ms/step - accuracy: 0.3968 - loss: 0.0135\nEpoch 6/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 28ms/step - accuracy: 0.3957 - loss: 0.0081\nEpoch 7/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 28ms/step - accuracy: 0.3973 - loss: 0.0055\nEpoch 8/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 28ms/step - accuracy: 0.3976 - loss: 0.0041\nEpoch 9/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 28ms/step - accuracy: 0.3971 - loss: 0.0032\nEpoch 10/10\n\u001b[1m3774/3774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 28ms/step - accuracy: 0.3975 - loss: 0.0026\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c1a3f419450>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"Создадим класс для генерации с помощью обученной модели","metadata":{}},{"cell_type":"code","source":"class TextGenerator:\n    \n    def __init__(self, model, sp_model, max_length, temperature):\n\n        self.model = model\n        self.sp_model = sp_model\n        self.max_length = max_length\n        self.temperature = temperature\n        self.bos_id = sp_model.bos_id()\n        self.eos_id = sp_model.eos_id()\n        self.pad_id = sp_model.pad_id()\n        self.unk_id = sp_model.unk_id()\n        \n    def preprocess_text(self, text):\n        encoded = self.sp_model.encode(text)\n        if len(encoded) > self.max_length - 2:\n            encoded = encoded[:self.max_length - 2]\n        sequence = encoded\n        if len(sequence) < self.max_length:\n            sequence = sequence + [self.pad_id] * (self.max_length - len(sequence))\n        else:\n            sequence = sequence[:self.max_length]\n        return np.array([sequence])\n    \n    def sample_next_token(self, logits):\n        logits = logits / self.temperature\n        probs = np.exp(logits) / np.sum(np.exp(logits))\n        return np.random.choice(len(probs), p=probs)\n    \n    def generate_sequence(self, prompt, max_gen_length = 50):\n        input_sequence = self.preprocess_text(prompt)\n        current_length = np.sum(input_sequence[0] != self.pad_id)\n        generated_tokens = []\n        \n        for i in range(self.max_length):\n            if current_length >= self.max_length:\n                break\n            predictions = self.model.predict(input_sequence, verbose=0)\n            last_token_logits = predictions[0, current_length - 1, :]\n            next_token = self.sample_next_token(last_token_logits)\n            input_sequence[0, current_length] = next_token\n            generated_tokens.append(next_token)\n            current_length += 1\n        \n        if prompt:\n            generated_text = self.sp_model.decode(generated_tokens)\n            return prompt + generated_text\n        else:\n            all_tokens = input_sequence[0][:current_length].tolist()\n            if all_tokens and all_tokens[0] == self.bos_id:\n                all_tokens = all_tokens[1:]\n            return self.sp_model.decode(all_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:05:56.840406Z","iopub.execute_input":"2025-12-12T14:05:56.840805Z","iopub.status.idle":"2025-12-12T14:05:56.849736Z","shell.execute_reply.started":"2025-12-12T14:05:56.840780Z","shell.execute_reply":"2025-12-12T14:05:56.848965Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"Сгенерируем последовательность по промпту","metadata":{}},{"cell_type":"code","source":"generator = TextGenerator(model=model, sp_model=dataset.sp_model, max_length=100, temperature=0.8)\nprompt = \"Анекдот\"\ngenerated = generator.generate_sequence(prompt=prompt)\ngenerated","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:05:58.340318Z","iopub.execute_input":"2025-12-12T14:05:58.340558Z","iopub.status.idle":"2025-12-12T14:06:04.211897Z","shell.execute_reply.started":"2025-12-12T14:05:58.340541Z","shell.execute_reply":"2025-12-12T14:06:04.211143Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'Анекдотак сказал зап закры запа каждо клаить государ заня тутбыного ино занима случатный твойвом стоит мар.- выпу ту против блиндешь папактор крожил уби рабо этой подходит соност человек зво соба,паатдом расвтоняхшать думаю?денок, эвить! апские кла работатьльный ша оргасемскогоэ сразу ту которая амери некостит владими когда прекра длянымичился сто говор человего девушки постели слулет студен шиниид конекро'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"with open('generate_result.txt', 'w') as file:\n    file.write(generated)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T14:06:33.326650Z","iopub.execute_input":"2025-12-12T14:06:33.327252Z","iopub.status.idle":"2025-12-12T14:06:33.331120Z","shell.execute_reply.started":"2025-12-12T14:06:33.327225Z","shell.execute_reply":"2025-12-12T14:06:33.330308Z"}},"outputs":[],"execution_count":22}]}